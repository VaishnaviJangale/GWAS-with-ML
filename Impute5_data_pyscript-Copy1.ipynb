{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Import libraries<span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 20:37:03.363001: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-20 20:37:03.363078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-20 20:37:03.364081: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-20 20:37:03.372784: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-20 20:37:04.551254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#Import all the required libraries\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, ReLU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import pybiomart\n",
    "from biomart import BiomartServer\n",
    "from sklearn.feature_selection import RFECV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> ML for Feature Selection and Association <span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FID  IID  PAT  MAT  SEX  PHENOTYPE  rs11253478_C  rs2436029:269101:C:T_T  \\\n",
      "0  10004    1    0    0    2         75             2                       2   \n",
      "1  10005    1    0    0    1         69             2                       2   \n",
      "2  10007    1    0    0    1        108             2                       2   \n",
      "3  10008    1    0    0    1         94             1                       2   \n",
      "4  10009    1    0    0    1         92             2                       2   \n",
      "\n",
      "   rs2448378_T  rs2060138_A  ...  rs11137278_C  rs6559242_G  rs1110146_T  \\\n",
      "0            2            1  ...             0            2            2   \n",
      "1            2            2  ...             2            0            2   \n",
      "2            2            2  ...             2            1            1   \n",
      "3            2            1  ...             2            1            2   \n",
      "4            2            2  ...             2            0            1   \n",
      "\n",
      "   rs6559257_A  rs7865267_C  rs1378954:141005656:G:A_A  \\\n",
      "0            2            2                          2   \n",
      "1            1            2                          2   \n",
      "2            1            2                          2   \n",
      "3            2            2                          2   \n",
      "4            2            2                          2   \n",
      "\n",
      "   rs766373:141005772:A:G_G  rs2739258_T  rs9777369_C  \\\n",
      "0                         2            1            2   \n",
      "1                         2            0            2   \n",
      "2                         2            0            2   \n",
      "3                         2            0            2   \n",
      "4                         1            1            2   \n",
      "\n",
      "   rs7863719:141071475:C:G_G  \n",
      "0                          2  \n",
      "1                          2  \n",
      "2                          2  \n",
      "3                          2  \n",
      "4                          2  \n",
      "\n",
      "[5 rows x 150131 columns]\n",
      "Shape of file (1282, 150131)\n"
     ]
    }
   ],
   "source": [
    "#Read the file \n",
    "df= pd.read_table(\"/home/Vaishnavi/Imputeted_data/GWAStutorialldlraw.raw\", delim_whitespace= True)\n",
    "print(df.head())\n",
    "print(\"Shape of file\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (1282, 150125)\n",
      "Shape of y (1282,)\n"
     ]
    }
   ],
   "source": [
    "#X is Independent feature and y is dependent feature\n",
    "X= df.iloc[:, 6:]\n",
    "print(\"Shape of X\", X.shape)\n",
    "y= df.PHENOTYPE\n",
    "print(\"Shape of y\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        75\n",
       "1        69\n",
       "2       108\n",
       "3        94\n",
       "4        92\n",
       "       ... \n",
       "1277    174\n",
       "1278     89\n",
       "1279     77\n",
       "1280     41\n",
       "1281     96\n",
       "Name: PHENOTYPE, Length: 1282, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of X_train is (897, 150125)\n",
      "The dimension of X_test is (385, 150125)\n"
     ]
    }
   ],
   "source": [
    "#Train test data split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=2000)\n",
    "print(\"The dimension of X_train is {}\".format(X_train.shape))\n",
    "print(\"The dimension of X_test is {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization of X_train and X_test data by Standard Scaler\n",
    "scaler= StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-squared function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_score_manual(y_true, y_pred):\n",
    "    # Convert inputs to NumPy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Calculate the mean of the actual values\n",
    "    y_mean = np.mean(y_true)\n",
    "    \n",
    "    # Residual sum of squares\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    \n",
    "    # Total sum of squares\n",
    "    ss_tot = np.sum((y_true - y_mean) ** 2)\n",
    "    \n",
    "    # RÂ² score\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> LASSO <span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.057e+02, tolerance: 1.336e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.817e+02, tolerance: 1.342e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.600e+02, tolerance: 1.252e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.725e+02, tolerance: 1.270e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.725e+02, tolerance: 1.218e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.943e+02, tolerance: 1.605e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.00062\n",
      "5000 selected SNPs\n",
      "print shape of selected snps by lasso (1282, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the LASSOCV model select 5000 SNP\n",
    "lasso_cv = linear_model.LassoCV(alphas= [0.00062], cv=5, random_state=2000)\n",
    "\n",
    "# Fit the model to the data\n",
    "lasso_cv.fit(X,y)\n",
    "\n",
    "#Print the optimal alpha value\n",
    "print (\"Optimal alpha:\", lasso_cv.alpha_)\n",
    "\n",
    "# Indices of the SNPs with non-zero coefficients\n",
    "lasso_snps_ldl = np.where(lasso_cv.coef_)[0]\n",
    "\n",
    "# See how many SNPs have a non-zero coefficient\n",
    "print(len(lasso_snps_ldl), \"selected SNPs\")\n",
    "\n",
    "#Final SNPs\n",
    "l1= X.iloc[:,lasso_snps_ldl]\n",
    "print(\"print shape of selected snps by lasso\",l1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape (1282,)\n",
      "x_train=(897, 5000), x_test=(385, 5000), Y_train= (897,), Y_test= (385,)\n",
      "r2 is  0.6835509848592075\n",
      "r2 is  0.6835509848592075\n",
      "mean_absolute_error 14.699557894419062\n",
      "mean_squared_error  340.5430770142561\n",
      "explained_variance_score 0.6843293027084176\n"
     ]
    }
   ],
   "source": [
    "Y= df.PHENOTYPE.values\n",
    "print(\"Y.shape\",Y.shape)\n",
    "x_train, x_test, Y_train, Y_test= train_test_split(l1, Y, test_size=0.3, random_state=2000)\n",
    "print(f\"x_train={x_train.shape}, x_test={x_test.shape}, Y_train= {Y_train.shape}, Y_test= {Y_test.shape}\")\n",
    "scaler= StandardScaler()\n",
    "x_train= scaler.fit_transform(x_train)\n",
    "x_test= scaler.transform(x_test)\n",
    "\n",
    "random.seed(2000)\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x_train, Y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "\n",
    "#f_statistic, p_value = f_regression(l1, Y)\n",
    "#selected_p_indices = np.where(p_value < 5e-04)[0]\n",
    "#selected_p_values = p_value[selected_p_indices]\n",
    "#print(\"Selected p-values:\")\n",
    "#print(selected_p_values)\n",
    "#print(\"Number of selected features:\", len(selected_p_indices))\n",
    "#selected_f_values = f_statistic[selected_p_indices]\n",
    "#print(\"Selected F-values:\")\n",
    "#print(selected_f_values)\n",
    "#top_f_indices = np.argsort(-selected_f_values)\n",
    "#print(\"Indices of selected features with top F-values:\")\n",
    "#print(top_f_indices)\n",
    "#top_f_features = l1.iloc[:, selected_p_indices[top_f_indices]]\n",
    "#print(\"Top selected features:\")\n",
    "#print(top_f_features)\n",
    "#lasso_LR_sigSNP=l1.iloc[:, selected_p_indices]\n",
    "#lasso_LR_sigSNP\n",
    "#lasso_LR_sig_col= list(lasso_LR_sigSNP.columns)\n",
    "#lasso_LR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.04964572853905869\n",
      "r2 is  0.04964572853905869\n",
      "mean_absolute_error 26.107939565289787\n",
      "mean_squared_error  1022.7131461065229\n",
      "explained_variance_score 0.05365766104291181\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Regressor\n",
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=9, min_samples_leaf=4, min_samples_split=2, \n",
    "                                     n_jobs=70,random_state=2000)\n",
    "\n",
    "rf_regressor.fit(x_train, Y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set using the model with selected features\n",
    "y_pred= rf_regressor.predict(x_test)\n",
    "\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.7034015854667354\n",
      "r2 is  0.7034015854667354\n",
      "mean_absolute_error 14.318335398926672\n",
      "mean_squared_error  319.1810746441081\n",
      "explained_variance_score 0.7042333593187404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "svr = SVR(kernel = 'sigmoid' , C=100, epsilon= 0.01, gamma= 'scale', cache_size=800)\n",
    "svr.fit(x_train, Y_train)\n",
    "y_pred= svr.predict(x_test)\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score -0.03410800025870375\n",
      "r2 is  -0.03410800025870375\n",
      "mean_absolute_error 26.652027932699625\n",
      "mean_squared_error  1112.8437869098063\n",
      "explained_variance_score -0.0317069362126432\n"
     ]
    }
   ],
   "source": [
    "regressor=xgb.XGBRegressor(learning_rate= 0.01, n_estimators=900,  max_depth=10, eval_metric='rmsle', random_state=2000)\n",
    "regressor.fit(x_train, Y_train)\n",
    "y_pred= regressor.predict(x_test)\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 score\",score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Ridge<span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.005\n",
      "Selected SNPs indices based on top coefficients: [108972  11284  94133 ...  17089 134652  72090]\n",
      "5000 selected SNPs\n",
      "Maximum value of coefficient 0.09102136750922467\n",
      "print shape of selected snps by Ridge (1282, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the RidgeCV model select 5000 SNP\n",
    "ridge_cv = linear_model.RidgeCV(alphas=[0.005], cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_cv.fit(X, y)\n",
    "\n",
    "# Optimal alpha value\n",
    "print(\"Optimal alpha:\", ridge_cv.alpha_)\n",
    "\n",
    "# Indices of the SNPs with non-zero coefficients\n",
    "ridge_snps_ldl = np.where(ridge_cv.coef_)[0]\n",
    "\n",
    "# Select coefficients with non-zero values\n",
    "selected_features = ridge_cv.coef_ != 0\n",
    "\n",
    "# Select coefficients of selected SNPs\n",
    "coefficients = ridge_cv.coef_[selected_features]\n",
    "\n",
    "# Get the indices of the top 5000 SNPs based on descending coefficients\n",
    "top_n = 5000\n",
    "sorted_indices = np.argsort(-coefficients)\n",
    "selected_indices = sorted_indices[:top_n]\n",
    "\n",
    "# Print the indices of selected SNPs and the number of selected SNPs\n",
    "print(\"Selected SNPs indices based on top coefficients:\", selected_indices)\n",
    "print(len(selected_indices), \"selected SNPs\")\n",
    "\n",
    "#Maximum Coefficient\n",
    "print(\"Maximum value of coefficient\", coefficients.max())\n",
    "\n",
    "#Final SNPs\n",
    "R1= X.iloc[:,selected_indices]\n",
    "print(\"print shape of selected snps by Ridge\",R1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape (1282,)\n",
      "x_train=(897, 5000), x_test=(385, 5000), Y_train= (897,), Y_test= (385,)\n"
     ]
    }
   ],
   "source": [
    "Y= df.PHENOTYPE.values\n",
    "print(\"Y.shape\",Y.shape)\n",
    "x_train, x_test, Y_train, Y_test= train_test_split(R1, Y, test_size=0.3, random_state=2000)\n",
    "print(f\"x_train={x_train.shape}, x_test={x_test.shape}, Y_train= {Y_train.shape}, Y_test= {Y_test.shape}\")\n",
    "scaler= StandardScaler()\n",
    "x_train= scaler.fit_transform(x_train)\n",
    "x_test= scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.8506717066436066\n",
      "r2 is  0.8506717066436066\n",
      "mean_absolute_error 10.274421623556924\n",
      "mean_squared_error  160.69797683601143\n",
      "explained_variance_score 0.8507279185220166\n"
     ]
    }
   ],
   "source": [
    "random.seed(2000)\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x_train, Y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "\n",
    "#f_statistic, p_value = f_regression(R1, Y)\n",
    "#selected_p_indices = np.where(p_value < 5e-04)[0]\n",
    "#selected_p_values = p_value[selected_p_indices]\n",
    "#print(\"Selected p-values:\")\n",
    "#print(selected_p_values)\n",
    "#print(\"Number of selected features:\", len(selected_p_indices))\n",
    "#selected_f_values = f_statistic[selected_p_indices]\n",
    "#print(\"Selected F-values:\")\n",
    "#print(selected_f_values)\n",
    "#top_f_indices = np.argsort(-selected_f_values)\n",
    "#print(\"Indices of selected features with top F-values:\")\n",
    "#print(top_f_indices)\n",
    "#top_f_features = R1.iloc[:, selected_p_indices[top_f_indices]]\n",
    "#print(\"Top selected features:\")\n",
    "#print(top_f_features)\n",
    "#Ridge_LR_sigSNP=R1.iloc[:, selected_p_indices]\n",
    "#Ridge_LR_sigSNP\n",
    "#Ridge_LR_sig_col= list(Ridge_LR_sigSNP.columns)\n",
    "#Ridge_LR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.06849734783798322\n",
      "r2 is  0.06849734783798322\n",
      "mean_absolute_error 25.765898278266828\n",
      "mean_squared_error  1002.4261863259692\n",
      "explained_variance_score 0.075142883876264\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Regressor\n",
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=9, min_samples_leaf=4, min_samples_split=2, \n",
    "                                     n_jobs=70,random_state=2000)\n",
    "\n",
    "rf_regressor.fit(x_train, Y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set using the model with selected features\n",
    "y_pred= rf_regressor.predict(x_test)\n",
    "\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.8407897808398864\n",
      "r2 is  0.8407897808398864\n",
      "mean_absolute_error 10.647254491629846\n",
      "mean_squared_error  171.3323010367937\n",
      "explained_variance_score 0.8408442684719689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "svr = SVR(kernel = 'sigmoid' , C=100, epsilon= 0.01, gamma= 'scale', cache_size=800)\n",
    "svr.fit(x_train, Y_train)\n",
    "y_pred= svr.predict(x_test)\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "\n",
    "\n",
    "#perm_importance= permutation_importance(svr, x_test, Y_test, n_repeats=10, random_state=2000, n_jobs=70)\n",
    "\n",
    "#imp_score=perm_importance.importances_mean\n",
    "#feature_indices = np.argsort(np.abs(imp_score))[::-1]\n",
    "#print(f\"Selected feature indices are {feature_indices}\")\n",
    "\n",
    "# # Specify the number of features you want to select based on magnitude\n",
    "#num_selected_features = 100\n",
    "#top_100=feature_indices[:num_selected_features]\n",
    "#print(f\"Top 100 fearure indices are {feature_indices}\")\n",
    "#imp_score_100=imp_score[top_100]\n",
    "#print(f\"Top 100 fearures permutation scores are {imp_score_100}\")\n",
    "\n",
    "#Ridge_SVR_sigSNP= R1.iloc[:,top_100]\n",
    "#Ridge_SVR_sig_col= list(Ridge_SVR_sigSNP.columns)\n",
    "#Ridge_SVR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score -0.04370920401631073\n",
      "r2 is  -0.04370920401631073\n",
      "mean_absolute_error 27.09141607903815\n",
      "mean_squared_error  1123.1760152126865\n",
      "explained_variance_score -0.03338318094447423\n"
     ]
    }
   ],
   "source": [
    "regressor=xgb.XGBRegressor(learning_rate= 0.01, n_estimators=900,  max_depth=10, eval_metric='rmsle', random_state=2000)\n",
    "regressor.fit(x_train, Y_train)\n",
    "y_pred= regressor.predict(x_test)\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 score\",score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Elastic net<span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.742e+02, tolerance: 1.336e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+02, tolerance: 1.342e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+02, tolerance: 1.252e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+02, tolerance: 1.270e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.351e+02, tolerance: 1.218e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.045\n",
      "Optimal l1_ratio:  0.5\n",
      "5000 selected SNPs\n",
      "print shape of selected snps by Elastic net (1282, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the Elasticnet model\n",
    "elastic_cv = linear_model.ElasticNetCV(l1_ratio=[0.5],alphas=[0.045], cv=5, random_state= 2000)\n",
    "elastic_cv.fit(X, y)\n",
    "\n",
    "# Print the optimal alpha value\n",
    "print (\"Optimal alpha:\", elastic_cv.alpha_)\n",
    "print(\"Optimal l1_ratio: \", elastic_cv.l1_ratio_)\n",
    "\n",
    "# Indices of the SNPs with non-zero coefficients\n",
    "elastic_snps_ldl = np.where(elastic_cv.coef_)[0]\n",
    "\n",
    "# See how many SNPs have a non-zero coefficient\n",
    "print(len(elastic_snps_ldl), \"selected SNPs\")\n",
    "\n",
    "#Final SNPs\n",
    "E1= X.iloc[:,elastic_snps_ldl]\n",
    "print(\"print shape of selected snps by Elastic net\",E1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape (1282,)\n",
      "x_train=(897, 5000), x_test=(385, 5000), Y_train= (897,), Y_test= (385,)\n"
     ]
    }
   ],
   "source": [
    "Y= df.PHENOTYPE.values\n",
    "print(\"Y.shape\",Y.shape)\n",
    "x_train, x_test, Y_train, Y_test= train_test_split(E1, Y, test_size=0.3, random_state=2000)\n",
    "print(f\"x_train={x_train.shape}, x_test={x_test.shape}, Y_train= {Y_train.shape}, Y_test= {Y_test.shape}\")\n",
    "scaler= StandardScaler()\n",
    "x_train= scaler.fit_transform(x_train)\n",
    "x_test= scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.9266011671336322\n",
      "r2 is  0.9266011671336322\n",
      "mean_absolute_error 7.2949537183920246\n",
      "mean_squared_error  78.98733507654364\n",
      "explained_variance_score 0.9266095503165738\n"
     ]
    }
   ],
   "source": [
    "random.seed(2000)\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x_train, Y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "\n",
    "#f_statistic, p_value = f_regression(E1, Y)\n",
    "#selected_p_indices = np.where(p_value < 5e-04)[0]\n",
    "#selected_p_values = p_value[selected_p_indices]\n",
    "#print(\"Selected p-values:\")\n",
    "#print(selected_p_values)\n",
    "#print(\"Number of selected features:\", len(selected_p_indices))\n",
    "#selected_f_values = f_statistic[selected_p_indices]\n",
    "#print(\"Selected F-values:\")\n",
    "#print(selected_f_values)\n",
    "#top_f_indices = np.argsort(-selected_f_values)\n",
    "#print(\"Indices of selected features with top F-values:\")\n",
    "#print(top_f_indices)\n",
    "#top_f_features = E1.iloc[:, selected_p_indices[top_f_indices]]\n",
    "#print(\"Top selected features:\")\n",
    "#print(top_f_features)\n",
    "#Elasticnet_LR_sigSNP=E1.iloc[:, selected_p_indices]\n",
    "#Elasticnet_LR_sigSNP\n",
    "#Elasticnet_LR_sig_col= list(Elasticnet_LR_sigSNP.columns)\n",
    "#Elasticnet_LR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.10045828387770017\n",
      "r2 is  0.10045828387770017\n",
      "mean_absolute_error 25.43497567580952\n",
      "mean_squared_error  968.0317815957836\n",
      "explained_variance_score 0.10187381796567085\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Regressor\n",
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=9, min_samples_leaf=4, min_samples_split=2, \n",
    "                                     n_jobs=70,random_state=2000)\n",
    "\n",
    "rf_regressor.fit(x_train, Y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set using the model with selected features\n",
    "y_pred= rf_regressor.predict(x_test)\n",
    "\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.9489763648346148\n",
      "r2 is  0.9489763648346148\n",
      "mean_absolute_error 6.00284057179963\n",
      "mean_squared_error  54.90851571126669\n",
      "explained_variance_score 0.9489864488835495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "svr = SVR(kernel = 'sigmoid' , C=100, epsilon= 0.01, gamma= 'scale', cache_size=800)\n",
    "svr.fit(x_train, Y_train)\n",
    "y_pred= svr.predict(x_test)\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score 0.047884105014666556\n",
      "r2 is  0.047884105014666556\n",
      "mean_absolute_error 26.06981248731737\n",
      "mean_squared_error  1024.6088976078202\n",
      "explained_variance_score 0.050348135679062156\n"
     ]
    }
   ],
   "source": [
    "regressor=xgb.XGBRegressor(learning_rate= 0.01, n_estimators=900,  max_depth=10, eval_metric='rmsle', random_state=2000)\n",
    "regressor.fit(x_train, Y_train)\n",
    "y_pred= regressor.predict(x_test)\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 score\",score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Mutual information <span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of mutal info 150125\n",
      "Maximum value of mutualinfo <bound method NDFrame._add_numeric_operations.<locals>.max of rs2454962_T     8.227665e-02\n",
      "rs379387_C      7.688184e-02\n",
      "rs7116167_T     7.608883e-02\n",
      "rs2198207_C     7.377785e-02\n",
      "rs2581623_T     7.361112e-02\n",
      "                    ...     \n",
      "rs9315776_G     1.771523e-06\n",
      "rs11855700_T    1.480320e-06\n",
      "rs2251611_G     1.455906e-06\n",
      "rs8042116_T     8.360537e-07\n",
      "rs12128709_G    3.290196e-07\n",
      "Length: 74209, dtype: float64>\n",
      "Length of mutal info non zero 74209\n",
      "print shape of selected snps by Mutual_info (1282, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the Mutual_info model\n",
    "mutual_info= mutual_info_regression(X, y, random_state=2000)\n",
    "print(\"Length of mutal info\", len(mutual_info))\n",
    "mutual_info= pd.Series(mutual_info, index=df.columns[6:])\n",
    "\n",
    "#Sort mutual_info values descending order\n",
    "vdesc= mutual_info.sort_values(ascending=False)\n",
    "vdesc_nonzero= vdesc[vdesc!=0]\n",
    "print(\"Maximum value of mutualinfo\", vdesc_nonzero.max)\n",
    "print(\"Length of mutal info non zero\", len(vdesc_nonzero))\n",
    "k= np.where(vdesc_nonzero)\n",
    "first_col= k[0]\n",
    "\n",
    "#Selected 5000 SNPs\n",
    "top5000 = 5000\n",
    "mi_pos= first_col[:top5000]\n",
    "\n",
    "#Final SNPs\n",
    "M1= X.iloc[:,mi_pos]\n",
    "print(\"print shape of selected snps by Mutual_info\",M1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape (1282,)\n",
      "x_train=(897, 5000), x_test=(385, 5000), Y_train= (897,), Y_test= (385,)\n"
     ]
    }
   ],
   "source": [
    "Y= df.PHENOTYPE.values\n",
    "print(\"Y.shape\",Y.shape)\n",
    "x_train, x_test, Y_train, Y_test= train_test_split(M1, Y, test_size=0.3, random_state=2000)\n",
    "print(f\"x_train={x_train.shape}, x_test={x_test.shape}, Y_train= {Y_train.shape}, Y_test= {Y_test.shape}\")\n",
    "scaler= StandardScaler()\n",
    "x_train= scaler.fit_transform(x_train)\n",
    "x_test= scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  -0.3549949068648166\n",
      "r2 is  -0.3549949068648166\n",
      "mean_absolute_error 30.88086267645026\n",
      "mean_squared_error  1458.162651310802\n",
      "explained_variance_score -0.3548642605452863\n"
     ]
    }
   ],
   "source": [
    "random.seed(2000)\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x_train, Y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "\n",
    "#f_statistic, p_value = f_regression(M1, Y)\n",
    "#selected_p_indices = np.where(p_value < 5e-04)[0]\n",
    "#selected_p_values = p_value[selected_p_indices]\n",
    "#print(\"Selected p-values:\")\n",
    "#print(selected_p_values)\n",
    "#print(\"Number of selected features:\", len(selected_p_indices))\n",
    "#selected_f_values = f_statistic[selected_p_indices]\n",
    "#print(\"Selected F-values:\")\n",
    "#print(selected_f_values)\n",
    "#top_f_indices = np.argsort(-selected_f_values)\n",
    "#print(\"Indices of selected features with top F-values:\")\n",
    "#print(top_f_indices)\n",
    "#top_f_features = M1.iloc[:, selected_p_indices[top_f_indices]]\n",
    "#print(\"Top selected features:\")\n",
    "#print(top_f_features)\n",
    "#MI_LR_sigSNP=M1.iloc[:, selected_p_indices]\n",
    "#MI_LR_sigSNP\n",
    "#MI_LR_sig_col= list(MI_LR_sigSNP.columns)\n",
    "#MI_LR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  -0.01145467568966807\n",
      "r2 is  -0.01145467568966807\n",
      "mean_absolute_error 26.826803813776582\n",
      "mean_squared_error  1088.4656644185422\n",
      "explained_variance_score -0.010302914736393998\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Regressor\n",
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=9, min_samples_leaf=4, min_samples_split=2, \n",
    "                                     n_jobs=70,random_state=2000)\n",
    "\n",
    "rf_regressor.fit(x_train, Y_train)\n",
    "\n",
    "\n",
    "# Make predictions on the test set using the model with selected features\n",
    "y_pred= rf_regressor.predict(x_test)\n",
    "\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  -0.45097301701422765\n",
      "r2 is  -0.45097301701422765\n",
      "mean_absolute_error 31.411199609285006\n",
      "mean_squared_error  1561.448423717936\n",
      "explained_variance_score -0.4484188686735737\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(kernel = 'sigmoid' , C=100, epsilon= 0.01, gamma= 'scale')\n",
    "svr.fit(x_train, Y_train)\n",
    "y_pred= svr.predict(x_test)\n",
    "\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 is \", score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score -0.08999244808581452\n",
      "r2 is  -0.08999244808581452\n",
      "mean_absolute_error 27.327849866198253\n",
      "mean_squared_error  1172.9832119347816\n",
      "explained_variance_score -0.08982811053637163\n"
     ]
    }
   ],
   "source": [
    "regressor=xgb.XGBRegressor(learning_rate= 0.01, n_estimators=900,  max_depth=10, eval_metric='rmsle', random_state=2000)\n",
    "regressor.fit(x_train, Y_train)\n",
    "y_pred= regressor.predict(x_test)\n",
    "score= r2_score(Y_test, y_pred)\n",
    "print(\"r2 score\",score)\n",
    "r2_man = r2_score_manual(Y_test, y_pred)\n",
    "print(\"r2 is \",r2_man)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
