{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> Import libraries<span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 15:56:09.091752: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-17 15:56:09.091815: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-17 15:56:09.092846: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-17 15:56:09.102346: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 15:56:10.072640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#Import all the required libraries\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn \n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, ReLU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import pybiomart\n",
    "from biomart import BiomartServer\n",
    "from sklearn.feature_selection import RFECV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\"> ML for Feature Selection and Association <span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file \n",
    "df= pd.read_table(\"/home/hapmap/240305193625/Plink/GWAStutorialldl_newraw.raw\", delim_whitespace=False)\n",
    "# print(df.head())\n",
    "# print(\"Shape of file\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FID</th>\n",
       "      <th>IID</th>\n",
       "      <th>PAT</th>\n",
       "      <th>MAT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PHENOTYPE</th>\n",
       "      <th>rs2905036_T</th>\n",
       "      <th>rs4245756_C</th>\n",
       "      <th>rs7537756_A</th>\n",
       "      <th>rs6694982_A</th>\n",
       "      <th>...</th>\n",
       "      <th>rs6644898_G</th>\n",
       "      <th>rs34605807_A</th>\n",
       "      <th>rs28600179_G</th>\n",
       "      <th>rs28655329_C</th>\n",
       "      <th>rs5982824_G</th>\n",
       "      <th>rs5939299_C</th>\n",
       "      <th>rs28814596_C</th>\n",
       "      <th>rs17653586_C</th>\n",
       "      <th>rs5983831_G</th>\n",
       "      <th>rs7876575_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NA19919</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1643.12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NA19916</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1622.42</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NA19835</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1603.07</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NA20282</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1634.15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NA19703</td>\n",
       "      <td>-9</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>1623.19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 184515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FID      IID  PAT  MAT  SEX  PHENOTYPE  rs2905036_T  rs4245756_C  \\\n",
       "0    1  NA19919   -9   -9    1    1643.12            2            2   \n",
       "1    1  NA19916   -9   -9    1    1622.42            1            2   \n",
       "2    1  NA19835   -9   -9    1    1603.07            2            2   \n",
       "3    1  NA20282   -9   -9    1    1634.15            2            2   \n",
       "4    1  NA19703   -9   -9    1    1623.19            2            2   \n",
       "\n",
       "   rs7537756_A  rs6694982_A  ...  rs6644898_G  rs34605807_A  rs28600179_G  \\\n",
       "0            2            2  ...            0             0             2   \n",
       "1            2            2  ...            0             1             1   \n",
       "2            2            1  ...            2             0             2   \n",
       "3            1            1  ...            1             1             2   \n",
       "4            1            2  ...            1             1             2   \n",
       "\n",
       "   rs28655329_C  rs5982824_G  rs5939299_C  rs28814596_C  rs17653586_C  \\\n",
       "0             1            0            2             2             2   \n",
       "1             2            1            1             2             2   \n",
       "2             2            1            2             2             2   \n",
       "3             1            1            1             2             2   \n",
       "4             1            1            2             2             2   \n",
       "\n",
       "   rs5983831_G  rs7876575_C  \n",
       "0            2            2  \n",
       "1            1            2  \n",
       "2            2            2  \n",
       "3            2            2  \n",
       "4            2            2  \n",
       "\n",
       "[5 rows x 184515 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FID', 'IID', 'PAT', 'MAT', 'SEX', 'PHENOTYPE', 'rs2905036',\n",
       "       'rs4245756', 'rs7537756', 'rs6694982',\n",
       "       ...\n",
       "       'rs6644898', 'rs34605807', 'rs28600179', 'rs28655329', 'rs5982824',\n",
       "       'rs5939299', 'rs28814596', 'rs17653586', 'rs5983831', 'rs7876575'],\n",
       "      dtype='object', length=184515)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_col_names= list(df.columns[:6])\n",
    "new_col_names.extend([col_name[:-2] for col_name in df.columns[6:]])\n",
    "df.columns=new_col_names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (1397, 184509)\n",
      "Shape of y (1397,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rs2905036</th>\n",
       "      <th>rs4245756</th>\n",
       "      <th>rs7537756</th>\n",
       "      <th>rs6694982</th>\n",
       "      <th>rs3748592</th>\n",
       "      <th>rs3748594</th>\n",
       "      <th>rs28391282</th>\n",
       "      <th>rs9777703</th>\n",
       "      <th>rs35940137</th>\n",
       "      <th>rs9697358</th>\n",
       "      <th>...</th>\n",
       "      <th>rs6644898</th>\n",
       "      <th>rs34605807</th>\n",
       "      <th>rs28600179</th>\n",
       "      <th>rs28655329</th>\n",
       "      <th>rs5982824</th>\n",
       "      <th>rs5939299</th>\n",
       "      <th>rs28814596</th>\n",
       "      <th>rs17653586</th>\n",
       "      <th>rs5983831</th>\n",
       "      <th>rs7876575</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1397 rows × 184509 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rs2905036  rs4245756  rs7537756  rs6694982  rs3748592  rs3748594  \\\n",
       "0             2          2          2          2          2          2   \n",
       "1             1          2          2          2          2          2   \n",
       "2             2          2          2          1          2          2   \n",
       "3             2          2          1          1          2          2   \n",
       "4             2          2          1          2          2          1   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1392          2          1          0          2          2          2   \n",
       "1393          2          1          1          2          1          2   \n",
       "1394          2          2          1          2          2          2   \n",
       "1395          2          2          0          2          2          2   \n",
       "1396          2          2          2          2          2          2   \n",
       "\n",
       "      rs28391282  rs9777703  rs35940137  rs9697358  ...  rs6644898  \\\n",
       "0              2          1           2          2  ...          0   \n",
       "1              2          2           2          2  ...          0   \n",
       "2              1          0           2          2  ...          2   \n",
       "3              2          1           2          2  ...          1   \n",
       "4              2          1           2          2  ...          1   \n",
       "...          ...        ...         ...        ...  ...        ...   \n",
       "1392           2          1           2          2  ...          2   \n",
       "1393           1          2           2          2  ...          2   \n",
       "1394           1          1           2          1  ...          1   \n",
       "1395           1          2           2          0  ...          1   \n",
       "1396           1          2           2          2  ...          1   \n",
       "\n",
       "      rs34605807  rs28600179  rs28655329  rs5982824  rs5939299  rs28814596  \\\n",
       "0              0           2           1          0          2           2   \n",
       "1              1           1           2          1          1           2   \n",
       "2              0           2           2          1          2           2   \n",
       "3              1           2           1          1          1           2   \n",
       "4              1           2           1          1          2           2   \n",
       "...          ...         ...         ...        ...        ...         ...   \n",
       "1392           2           2           1          2          1           2   \n",
       "1393           1           0           1          1          1           2   \n",
       "1394           1           2           0          1          1           2   \n",
       "1395           1           2           2          1          2           2   \n",
       "1396           0           2           1          1          1           2   \n",
       "\n",
       "      rs17653586  rs5983831  rs7876575  \n",
       "0              2          2          2  \n",
       "1              2          1          2  \n",
       "2              2          2          2  \n",
       "3              2          2          2  \n",
       "4              2          2          2  \n",
       "...          ...        ...        ...  \n",
       "1392           2          2          2  \n",
       "1393           2          2          2  \n",
       "1394           2          2          2  \n",
       "1395           2          1          2  \n",
       "1396           2          2          2  \n",
       "\n",
       "[1397 rows x 184509 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #X is Independent feature and y is dependent feature\n",
    "X= df.iloc[:, 6:]\n",
    "print(\"Shape of X\", X.shape)\n",
    "y= df.PHENOTYPE\n",
    "print(\"Shape of y\", y.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of X_train is (977, 184509)\n",
      "The dimension of X_test is (420, 184509)\n"
     ]
    }
   ],
   "source": [
    "#Train test data split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=2000)\n",
    "print(\"The dimension of X_train is {}\".format(X_train.shape))\n",
    "print(\"The dimension of X_test is {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization of X_train and X_test data by Standard Scaler\n",
    "scaler= StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test= scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1643.12\n",
       "1       1622.42\n",
       "2       1603.07\n",
       "3       1634.15\n",
       "4       1623.19\n",
       "         ...   \n",
       "1392    1614.51\n",
       "1393    1613.63\n",
       "1394    1622.67\n",
       "1395    1601.58\n",
       "1396    1639.02\n",
       "Name: PHENOTYPE, Length: 1397, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> LASSO <span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.513e+02, tolerance: 1.412e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.558e+02, tolerance: 1.374e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.719e+02, tolerance: 1.055e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.202e+02, tolerance: 1.393e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.916e+02, tolerance: 1.443e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.889e+02, tolerance: 1.673e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.0009\n",
      "5006 selected SNPs\n",
      "print shape of selected snps by lasso (1397, 5006)\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the LASSOCV model select 5000 SNP\n",
    "lasso_cv = linear_model.LassoCV(alphas= [0.0009], cv=5, random_state=2000, n_jobs=70)\n",
    "\n",
    "# Fit the model to the data\n",
    "lasso_cv.fit(X,y)\n",
    "\n",
    "#Print the optimal alpha value\n",
    "print (\"Optimal alpha:\", lasso_cv.alpha_)\n",
    "\n",
    "# Indices of the SNPs with non-zero coefficients\n",
    "lasso_snps_ldl = np.where(lasso_cv.coef_)[0]\n",
    "\n",
    "# See how many SNPs have a non-zero coefficient\n",
    "print(len(lasso_snps_ldl), \"selected SNPs\")\n",
    "\n",
    "#Final SNPs\n",
    "l1= X.iloc[:,lasso_snps_ldl]\n",
    "print(\"print shape of selected snps by lasso\",l1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape (1397,)\n",
      "x_train=(977, 5006), x_test=(420, 5006), Y_train= (977,), Y_test= (420,)\n",
      "r2 is  0.5791382482551777\n",
      "mean_absolute_error 12.465512537052506\n",
      "mean_squared_error  252.84025371490713\n",
      "explained_variance_score 0.782657089765626\n"
     ]
    }
   ],
   "source": [
    "Y= df.PHENOTYPE\n",
    "print(\"Y.shape\",Y.shape)\n",
    "x_train, x_test, Y_train, Y_test= train_test_split(l1, Y, test_size=0.3, random_state=2000)\n",
    "print(f\"x_train={x_train.shape}, x_test={x_test.shape}, Y_train= {Y_train.shape}, Y_test= {Y_test.shape}\")\n",
    "scaler= StandardScaler()\n",
    "x_train= scaler.fit_transform(x_train)\n",
    "x_test= scaler.transform(x_test)\n",
    "\n",
    "random.seed(2000)\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x_train, Y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "\n",
    "# f_statistic, p_value = f_regression(l1, Y)\n",
    "# selected_p_indices = np.where(p_value < 5e-04)[0]\n",
    "# selected_p_values = p_value[selected_p_indices]\n",
    "# print(\"Selected p-values:\")\n",
    "# print(selected_p_values)\n",
    "# print(\"Number of selected features:\", len(selected_p_indices))\n",
    "# selected_f_values = f_statistic[selected_p_indices]\n",
    "# print(\"Selected F-values:\")\n",
    "# print(selected_f_values)\n",
    "# top_f_indices = np.argsort(-selected_f_values)\n",
    "# print(\"Indices of selected features with top F-values:\")\n",
    "# print(top_f_indices)\n",
    "# top_f_features = l1.iloc[:, selected_p_indices[top_f_indices]]\n",
    "# print(\"Top selected features:\")\n",
    "# print(top_f_features)\n",
    "# lasso_LR_sigSNP=l1.iloc[:, selected_p_indices]\n",
    "# lasso_LR_sigSNP\n",
    "# lasso_LR_sig_col= list(lasso_LR_sigSNP.columns)\n",
    "# lasso_LR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  -1.1080667953243561\n",
      "mean_absolute_error 20.644516940231085\n",
      "mean_squared_error  697.633794355837\n",
      "explained_variance_score 0.40026529374490283\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Regressor\n",
    " #reate a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=9, min_samples_leaf=4, min_samples_split=2, \n",
    "                                     n_jobs=10,random_state=2000)\n",
    "\n",
    "# Create RFECV object\n",
    "# rfecv = RFECV(estimator=rf_regressor, step=30, cv=5, scoring='neg_mean_squared_error', n_jobs=20)\n",
    "\n",
    "# # Fit RFECV on the training data\n",
    "# rfecv.fit(x_train, Y_train)\n",
    "\n",
    "# # Manually set the number of features you want to keep\n",
    "# desired_num_features =100\n",
    "# # Manually set the number of features you want to keep\n",
    "\n",
    "\n",
    "# # Get the selected features based on the desired number\n",
    "# selected_features = rfecv.get_support(indices=True)[:desired_num_features]\n",
    "# # Print the indices of the selected features\n",
    "# print(\"Selected features indices:\", selected_features)\n",
    "\n",
    "# # Transform the training and testing data to keep only the selected features\n",
    "# X_train_selected = rfecv.transform(x_train)\n",
    "# X_test_selected = rfecv.transform(x_test)\n",
    "\n",
    "\n",
    "# # Get the optimal number of features\n",
    "# optimal_num_features = rfecv.n_features_\n",
    "\n",
    "# # Print the optimal number of features\n",
    "# #print(f\"Optimal number of features: {optimal_num_features}\")\n",
    "\n",
    "\n",
    "# # Train a Random Forest Regressor on the selected features\n",
    "# rf_regressor_selected = RandomForestRegressor(n_estimators=100, random_state=2000)\n",
    "rf_regressor.fit(x_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set using the model with selected features\n",
    "y_pred= rf_regressor.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "# lasso_RF_sigSNP=l1.iloc[:,selected_features]\n",
    "# lasso_RF_sig_col= list(lasso_RF_sigSNP.columns)\n",
    "# lasso_RF_sig_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.721099901900792\n",
      "mean_absolute_error 12.161761948920846\n",
      "mean_squared_error  239.6606379732451\n",
      "explained_variance_score 0.7938640460916601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "svr = SVR(kernel = 'sigmoid' , C=100, epsilon= 0.01, gamma= 'scale', cache_size=800)\n",
    "svr.fit(x_train, Y_train)\n",
    "y_pred= svr.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "# perm_importance= permutation_importance(svr, x_test, Y_test, n_repeats=10, random_state=2000, n_jobs=20)\n",
    "\n",
    "\n",
    "# imp_score=perm_importance.importances_mean\n",
    "# feature_indices = np.argsort(imp_score)[::-1]\n",
    "# print(f\"Selected feature indices are {feature_indices}\")\n",
    "\n",
    "# # # Specify the number of features you want to select based on magnitude\n",
    "# num_selected_features = 100\n",
    "# top_100=feature_indices[:num_selected_features]\n",
    "# print(f\"Top 100 fearure indices are {feature_indices}\")\n",
    "# imp_score_100=imp_score[top_100]\n",
    "# print(f\"Top 100 fearures permutation scores are {imp_score_100}\")\n",
    "# lasso_SVR_sigSNP= l1.iloc[:,top_100]\n",
    "# lasso_SVR_sig_col= list(lasso_SVR_sigSNP.columns)\n",
    "# lasso_SVR_sig_col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score -0.7567837899784347\n",
      "mean_absolute_error 21.47790563383557\n",
      "mean_squared_error  758.2477771266286\n",
      "explained_variance_score 0.3489553142514311\n"
     ]
    }
   ],
   "source": [
    "regressor=xgb.XGBRegressor(learning_rate= 0.01, n_estimators=900,  max_depth=10, eval_metric='rmsle', random_state=2000)\n",
    "regressor.fit(x_train, Y_train)\n",
    "y_pred= regressor.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 score\",score)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Ridge<span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.005\n",
      "Selected SNPs indices based on top coefficients: [ 49952 181233  21114 ... 178888 156978 130250]\n",
      "5000 selected SNPs\n",
      "Maximum value of coefficient 0.5110441437104237\n",
      "print shape of selected snps by Ridge (1397, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the RidgeCV model select 5000 SNP\n",
    "ridge_cv = linear_model.RidgeCV(alphas=[0.005], cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_cv.fit(X, y)\n",
    "\n",
    "# Optimal alpha value\n",
    "print(\"Optimal alpha:\", ridge_cv.alpha_)\n",
    "\n",
    "# Indices of the SNPs with non-zero coefficients\n",
    "ridge_snps_ldl = np.where(ridge_cv.coef_)[0]\n",
    "\n",
    "# Select coefficients with non-zero values\n",
    "selected_features = ridge_cv.coef_ != 0\n",
    "\n",
    "# Select coefficients of selected SNPs\n",
    "coefficients = ridge_cv.coef_[selected_features]\n",
    "\n",
    "# Get the indices of the top 5000 SNPs based on descending coefficients\n",
    "top_n = 5000\n",
    "sorted_indices = np.argsort(-coefficients)\n",
    "selected_indices = sorted_indices[:top_n]\n",
    "\n",
    "# Print the indices of selected SNPs and the number of selected SNPs\n",
    "print(\"Selected SNPs indices based on top coefficients:\", selected_indices)\n",
    "print(len(selected_indices), \"selected SNPs\")\n",
    "\n",
    "#Maximum Coefficient\n",
    "print(\"Maximum value of coefficient\", coefficients.max())\n",
    "\n",
    "#Final SNPs\n",
    "R1= X.iloc[:,selected_indices]\n",
    "print(\"print shape of selected snps by Ridge\",R1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape (1397,)\n",
      "x_train=(977, 5000), x_test=(420, 5000), Y_train= (977,), Y_test= (420,)\n"
     ]
    }
   ],
   "source": [
    "Y= df.PHENOTYPE\n",
    "print(\"Y.shape\",Y.shape)\n",
    "x_train, x_test, Y_train, Y_test= train_test_split(R1, Y, test_size=0.3, random_state=2000)\n",
    "print(f\"x_train={x_train.shape}, x_test={x_test.shape}, Y_train= {Y_train.shape}, Y_test= {Y_test.shape}\")\n",
    "scaler= StandardScaler()\n",
    "x_train= scaler.fit_transform(x_train)\n",
    "x_test= scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.7495365521265533\n",
      "mean_absolute_error 10.571163767740806\n",
      "mean_squared_error  184.09266646612926\n",
      "explained_variance_score 0.8419250391940631\n"
     ]
    }
   ],
   "source": [
    "random.seed(2000)\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x_train, Y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "\n",
    "# f_statistic, p_value = f_regression(R1, Y)\n",
    "# selected_p_indices = np.where(p_value < 5e-04)[0]\n",
    "# selected_p_values = p_value[selected_p_indices]\n",
    "# print(\"Selected p-values:\")\n",
    "# print(selected_p_values)\n",
    "# print(\"Number of selected features:\", len(selected_p_indices))\n",
    "# selected_f_values = f_statistic[selected_p_indices]\n",
    "# print(\"Selected F-values:\")\n",
    "# print(selected_f_values)\n",
    "# top_f_indices = np.argsort(-selected_f_values)\n",
    "# print(\"Indices of selected features with top F-values:\")\n",
    "# print(top_f_indices)\n",
    "# top_f_features = R1.iloc[:, selected_p_indices[top_f_indices]]\n",
    "# print(\"Top selected features:\")\n",
    "# print(top_f_features)\n",
    "# Ridge_LR_sigSNP=R1.iloc[:, selected_p_indices]\n",
    "# Ridge_LR_sigSNP\n",
    "# Ridge_LR_sig_col= list(Ridge_LR_sigSNP.columns)\n",
    "# Ridge_LR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  -25.458692490331657\n",
      "mean_absolute_error 24.130327097668317\n",
      "mean_squared_error  1037.776645500237\n",
      "explained_variance_score 0.10813911518407104\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=9, min_samples_leaf=4, min_samples_split=2, \n",
    "                                     n_jobs=20,random_state=2000)\n",
    "\n",
    "# Create RFECV object\n",
    "# rfecv = RFECV(estimator=rf_regressor, step=30, cv=5, scoring='neg_mean_squared_error', n_jobs=4)\n",
    "\n",
    "# # Fit RFECV on the training data\n",
    "# rfecv.fit(x_train, Y_train)\n",
    "\n",
    "# # Manually set the number of features you want to keep\n",
    "# desired_num_features =100\n",
    "# # Manually set the number of features you want to keep\n",
    "\n",
    "\n",
    "# # Get the selected features based on the desired number\n",
    "# selected_features = rfecv.get_support(indices=True)[:desired_num_features]\n",
    "# # Print the indices of the selected features\n",
    "# print(\"Selected features indices:\", selected_features)\n",
    "\n",
    "# # Transform the training and testing data to keep only the selected features\n",
    "# X_train_selected = rfecv.transform(x_train)[:, selected_features]\n",
    "# X_test_selected = rfecv.transform(x_test)[:, selected_features]\n",
    "\n",
    "\n",
    "# # Get the optimal number of features\n",
    "# optimal_num_features = rfecv.n_features_\n",
    "\n",
    "# # Print the optimal number of features\n",
    "#print(f\"Optimal number of features: {optimal_num_features}\")\n",
    "\n",
    "\n",
    "# Train a Random Forest Regressor on the selected features\n",
    "# rf_regressor_selected = RandomForestRegressor(n_estimators=100, random_state=2000)\n",
    "rf_regressor.fit(x_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set using the model with selected features\n",
    "y_pred = rf_regressor.predict(x_test)\n",
    "\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "# Ridge_RF_sigSNP=R1.iloc[:,selected_features]\n",
    "# Ridge_RF_sig_col= list(Ridge_RF_sigSNP.columns)\n",
    "# Ridge_RF_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.7444089301350973\n",
      "mean_absolute_error 12.862723241150734\n",
      "mean_squared_error  265.44715405167744\n",
      "explained_variance_score 0.7720143400428139\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "svr = SVR(kernel = 'sigmoid' , C=100, epsilon= 0.01, gamma= 'scale', cache_size=800)\n",
    "svr.fit(x_train, Y_train)\n",
    "y_pred= svr.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "# perm_importance= permutation_importance(svr, x_test, Y_test, n_repeats=10, random_state=2000, n_jobs=10)\n",
    "\n",
    "\n",
    "# imp_score=perm_importance.importances_mean\n",
    "# feature_indices = np.argsort(np.abs(imp_score))[::-1]\n",
    "# print(f\"Selected feature indices are {feature_indices}\")\n",
    "\n",
    "# # # Specify the number of features you want to select based on magnitude\n",
    "# num_selected_features = 100\n",
    "# top_100=feature_indices[:num_selected_features]\n",
    "# print(f\"Top 100 fearure indices are {feature_indices}\")\n",
    "# imp_score_100=imp_score[top_100]\n",
    "# print(f\"Top 100 fearures permutation scores are {imp_score_100}\")\n",
    "\n",
    "# Ridge_SVR_sigSNP= R1.iloc[:,top_100]\n",
    "# Ridge_SVR_sig_col= list(Ridge_SVR_sigSNP.columns)\n",
    "# Ridge_SVR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score -6.518809301431905\n",
      "mean_absolute_error 25.53861571103051\n",
      "mean_squared_error  1113.4154745956616\n",
      "explained_variance_score 0.04489672489733043\n"
     ]
    }
   ],
   "source": [
    "regressor=xgb.XGBRegressor(learning_rate= 0.01, n_estimators=900,  max_depth=10, eval_metric='rmsle', random_state=2000)\n",
    "regressor.fit(x_train, Y_train)\n",
    "y_pred= regressor.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 score\",score)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Elastic net<span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.644e+03, tolerance: 1.374e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.699e+03, tolerance: 1.443e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.903e+03, tolerance: 1.055e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.061e+03, tolerance: 1.393e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.731e+03, tolerance: 1.412e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/apps/compiler/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.753e+03, tolerance: 1.673e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha: 0.09\n",
      "Optimal l1_ratio:  0.5\n",
      "5234 selected SNPs\n",
      "print shape of selected snps by Elastic net (1397, 5234)\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the Elasticnet model\n",
    "elastic_cv = linear_model.ElasticNetCV(l1_ratio=[0.5],alphas=[0.09], cv=5, random_state= 2000, n_jobs=70)\n",
    "elastic_cv.fit(X, y)\n",
    "\n",
    "# Print the optimal alpha value\n",
    "print (\"Optimal alpha:\", elastic_cv.alpha_)\n",
    "print(\"Optimal l1_ratio: \", elastic_cv.l1_ratio_)\n",
    "\n",
    "# Indices of the SNPs with non-zero coefficients\n",
    "elastic_snps_ldl = np.where(elastic_cv.coef_)[0]\n",
    "\n",
    "# See how many SNPs have a non-zero coefficient\n",
    "print(len(elastic_snps_ldl), \"selected SNPs\")\n",
    "\n",
    "#Final SNPs\n",
    "E1= X.iloc[:,elastic_snps_ldl]\n",
    "print(\"print shape of selected snps by Elastic net\",E1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape (1397,)\n",
      "x_train=(977, 5234), x_test=(420, 5234), Y_train= (977, 5234), Y_test= (420,)\n"
     ]
    }
   ],
   "source": [
    "Y= df.PHENOTYPE\n",
    "print(\"Y.shape\",Y.shape)\n",
    "x_train, x_test, Y_train, Y_test= train_test_split(E1, Y, test_size=0.3, random_state=2000)\n",
    "print(f\"x_train={x_train.shape}, x_test={x_test.shape}, Y_train= {x_train.shape}, Y_test= {Y_test.shape}\")\n",
    "scaler= StandardScaler()\n",
    "x_train= scaler.fit_transform(x_train)\n",
    "x_test= scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.8942542279665269\n",
      "mean_absolute_error 7.360016430608836\n",
      "mean_squared_error  87.24261030890234\n",
      "explained_variance_score 0.9250345355808147\n"
     ]
    }
   ],
   "source": [
    "random.seed(2000)\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x_train, Y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "\n",
    "# f_statistic, p_value = f_regression(E1, Y)\n",
    "# selected_p_indices = np.where(p_value < 5e-04)[0]\n",
    "# selected_p_values = p_value[selected_p_indices]\n",
    "# print(\"Selected p-values:\")\n",
    "# print(selected_p_values)\n",
    "# print(\"Number of selected features:\", len(selected_p_indices))\n",
    "# selected_f_values = f_statistic[selected_p_indices]\n",
    "# print(\"Selected F-values:\")\n",
    "# print(selected_f_values)\n",
    "# top_f_indices = np.argsort(-selected_f_values)\n",
    "# print(\"Indices of selected features with top F-values:\")\n",
    "# print(top_f_indices)\n",
    "# top_f_features = E1.iloc[:, selected_p_indices[top_f_indices]]\n",
    "# print(\"Top selected features:\")\n",
    "# print(top_f_features)\n",
    "# Elasticnet_LR_sigSNP=E1.iloc[:, selected_p_indices]\n",
    "# Elasticnet_LR_sigSNP\n",
    "# Elasticnet_LR_sig_col= list(Elasticnet_LR_sigSNP.columns)\n",
    "# Elasticnet_LR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  -0.9569676130372007\n",
      "mean_absolute_error 20.184452330021944\n",
      "mean_squared_error  656.2532810317174\n",
      "explained_variance_score 0.4355302096863958\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=9, min_samples_leaf=4, min_samples_split=2, \n",
    "                                     n_jobs=20,random_state=2000)\n",
    "\n",
    "# # Create RFECV object\n",
    "# rfecv = RFECV(estimator=rf_regressor, step=30, cv=5, scoring='neg_mean_squared_error', n_jobs=70)\n",
    "\n",
    "# # Fit RFECV on the training data\n",
    "# rfecv.fit(x_train, Y_train)\n",
    "\n",
    "# # Manually set the number of features you want to keep\n",
    "# desired_num_features =100\n",
    "# # Manually set the number of features you want to keep\n",
    "\n",
    "\n",
    "# # Get the selected features based on the desired number\n",
    "# selected_features = rfecv.get_support(indices=True)[:desired_num_features]\n",
    "# # Print the indices of the selected features\n",
    "# print(\"Selected features indices:\", selected_features)\n",
    "\n",
    "# # Transform the training and testing data to keep only the selected features\n",
    "# X_train_selected = rfecv.transform(x_train)[:, selected_features]\n",
    "# X_test_selected = rfecv.transform(x_test)[:, selected_features]\n",
    "\n",
    "\n",
    "# # Get the optimal number of features\n",
    "# optimal_num_features = rfecv.n_features_\n",
    "\n",
    "# # Print the optimal number of features\n",
    "#print(f\"Optimal number of features: {optimal_num_features}\")\n",
    "\n",
    "\n",
    "# Train a Random Forest Regressor on the selected features\n",
    "# rf_regressor_selected = RandomForestRegressor(n_estimators=100, random_state=2000)\n",
    "rf_regressor.fit(x_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set using the model with selected features\n",
    "y_pred= rf_regressor.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "# Elasticnet_RF_sigSNP=E1.iloc[:,selected_features]\n",
    "# Elasticnet_RF_sig_col= list(Elasticnet_RF_sigSNP.columns)\n",
    "# Elasticnet_RF_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  0.9060954040455816\n",
      "mean_absolute_error 7.782449770546358\n",
      "mean_squared_error  98.74576826435285\n",
      "explained_variance_score 0.9150635119925715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "svr = SVR(kernel = 'sigmoid' , C=100, epsilon= 0.01, gamma= 'scale', cache_size=800)\n",
    "svr.fit(x_train, Y_train)\n",
    "y_pred= svr.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "#perm_importance= permutation_importance(svr, x_test, Y_test, n_repeats=10, random_state=2000, n_jobs=70)\n",
    "\n",
    "\n",
    "# imp_score=perm_importance.importances_mean\n",
    "# feature_indices = np.argsort(np.abs(imp_score))[::-1]\n",
    "# print(f\"Selected feature indices are {feature_indices}\")\n",
    "# # # Specify the number of features you want to select based on magnitude\n",
    "# num_selected_features = 100\n",
    "# top_100=feature_indices[:num_selected_features]\n",
    "# print(f\"Top 100 fearure indices are {feature_indices}\")\n",
    "# imp_score_100=imp_score[top_100]\n",
    "# print(f\"Top 100 fearures permutation scores are {imp_score_100}\")\n",
    "# Elasticnet_SVR_sigSNP= E1.iloc[:,top_100]\n",
    "# Elasticnet_SVR_sig_col= list(Elasticnet_SVR_sigSNP.columns)\n",
    "# Elasticnet_SVR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score -0.8781806156008922\n",
      "mean_absolute_error 21.23531454613095\n",
      "mean_squared_error  750.599068979581\n",
      "explained_variance_score 0.3547242389716916\n"
     ]
    }
   ],
   "source": [
    "regressor=xgb.XGBRegressor(learning_rate= 0.01, n_estimators=900,  max_depth=10, eval_metric='rmsle', random_state=2000)\n",
    "regressor.fit(x_train, Y_train)\n",
    "y_pred= regressor.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 score\",score)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Mutual information <span style=\"color:green\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of mutal info 184509\n",
      "Maximum value of mutualinfo <bound method NDFrame._add_numeric_operations.<locals>.max of rs35284732    1.076325e-01\n",
      "rs8183216     1.076325e-01\n",
      "rs9757258     1.076325e-01\n",
      "rs2173077     1.076325e-01\n",
      "rs11645945    1.076325e-01\n",
      "                  ...     \n",
      "rs7251578     9.338578e-07\n",
      "rs9494623     8.373688e-07\n",
      "rs1933517     6.334198e-07\n",
      "rs17090150    7.810892e-08\n",
      "rs16870291    2.609217e-08\n",
      "Length: 107237, dtype: float64>\n",
      "Length of mutal info non zero 107237\n",
      "print shape of selected snps by Mutual_info (1397, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the Mutual_info model\n",
    "mutual_info= mutual_info_regression(X, y, random_state=2000)\n",
    "print(\"Length of mutal info\", len(mutual_info))\n",
    "mutual_info= pd.Series(mutual_info, index=df.columns[6:])\n",
    "\n",
    "#Sort mutual_info values descending order\n",
    "vdesc= mutual_info.sort_values(ascending=False)\n",
    "vdesc_nonzero= vdesc[vdesc!=0]\n",
    "print(\"Maximum value of mutualinfo\", vdesc_nonzero.max)\n",
    "print(\"Length of mutal info non zero\", len(vdesc_nonzero))\n",
    "k= np.where(vdesc_nonzero)\n",
    "first_col= k[0]\n",
    "\n",
    "#Selected 5000 SNPs\n",
    "top5000 = 5000\n",
    "mi_pos= first_col[:top5000]\n",
    "\n",
    "#Final SNPs\n",
    "M1= X.iloc[:,mi_pos]\n",
    "print(\"print shape of selected snps by Mutual_info\",M1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape (1397,)\n",
      "x_train=(977, 5000), x_test=(420, 5000), Y_train= (977,), Y_test= (420,)\n"
     ]
    }
   ],
   "source": [
    "Y= df.PHENOTYPE.values\n",
    "print(\"Y.shape\",Y.shape)\n",
    "x_train, x_test, Y_train, Y_test= train_test_split(M1, Y, test_size=0.3, random_state=2000)\n",
    "print(f\"x_train={x_train.shape}, x_test={x_test.shape}, Y_train= {Y_train.shape}, Y_test= {Y_test.shape}\")\n",
    "scaler= StandardScaler()\n",
    "x_train= scaler.fit_transform(x_train)\n",
    "x_test= scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  -1.6731668601292902\n",
      "mean_absolute_error 32.10365117629098\n",
      "mean_squared_error  1783.8521895339607\n",
      "explained_variance_score -0.5325159636765415\n"
     ]
    }
   ],
   "source": [
    "random.seed(2000)\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x_train, Y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "\n",
    "# f_statistic, p_value = f_regression(M1, Y)\n",
    "# selected_p_indices = np.where(p_value < 5e-04)[0]\n",
    "# selected_p_values = p_value[selected_p_indices]\n",
    "# print(\"Selected p-values:\")\n",
    "# print(selected_p_values)\n",
    "# print(\"Number of selected features:\", len(selected_p_indices))\n",
    "# selected_f_values = f_statistic[selected_p_indices]\n",
    "# print(\"Selected F-values:\")\n",
    "# print(selected_f_values)\n",
    "# top_f_indices = np.argsort(-selected_f_values)\n",
    "# print(\"Indices of selected features with top F-values:\")\n",
    "# print(top_f_indices)\n",
    "# top_f_features = M1.iloc[:, selected_p_indices[top_f_indices]]\n",
    "# print(\"Top selected features:\")\n",
    "# print(top_f_features)\n",
    "# MI_LR_sigSNP=M1.iloc[:, selected_p_indices]\n",
    "# MI_LR_sigSNP\n",
    "# MI_LR_sig_col= list(MI_LR_sigSNP.columns)\n",
    "# MI_LR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 is  -27.231205947401545\n",
      "mean_absolute_error 25.116006879717293\n",
      "mean_squared_error  1133.080150880739\n",
      "explained_variance_score 0.025369276531193474\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, max_depth=9, min_samples_leaf=4, min_samples_split=2, \n",
    "                                     n_jobs=70,random_state=2000)\n",
    "\n",
    "# Create RFECV object\n",
    "# rfecv = RFECV(estimator=rf_regressor, step=30, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# # Fit RFECV on the training data\n",
    "# rfecv.fit(x_train, Y_train)\n",
    "\n",
    "# # Manually set the number of features you want to keep\n",
    "# desired_num_features =100\n",
    "# # Manually set the number of features you want to keep\n",
    "\n",
    "\n",
    "# # Get the selected features based on the desired number\n",
    "# selected_features = rfecv.support_\n",
    "# # Print the indices of the selected features\n",
    "# print(\"Selected features indices:\", selected_features)\n",
    "\n",
    "# # Transform the training and testing data to keep only the selected features\n",
    "# X_train_selected = rfecv.transform(x_train)\n",
    "# X_test_selected = rfecv.transform(x_test)\n",
    "\n",
    "\n",
    "# # Get the optimal number of features\n",
    "# optimal_num_features = rfecv.n_features_\n",
    "\n",
    "# # Print the optimal number of features\n",
    "# #print(f\"Optimal number of features: {optimal_num_features}\")\n",
    "\n",
    "\n",
    "# Train a Random Forest Regressor on the selected features\n",
    "#rf_regressor= RandomForestRegressor(n_estimators=100, random_state=2000)\n",
    "rf_regressor.fit(x_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set using the model with selected features\n",
    "y_pred= rf_regressor.predict(x_test)\n",
    "\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "# MI_RF_sigSNP=M1.iloc[:,selected_features]\n",
    "# MI_RF_sig_col= list(MI_RF_sigSNP.columns)\n",
    "# MI_RF_sig_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is 31.809512084671944\n",
      "r2 is  -1.946825585813118\n",
      "mean_absolute_error 31.809512084671944\n",
      "mean_squared_error  1765.1336316588079\n",
      "explained_variance_score -0.5183092884378504\n"
     ]
    }
   ],
   "source": [
    "svr = SVR(kernel = 'sigmoid' , C=100, epsilon= 0.01, gamma= 'scale')\n",
    "svr.fit(x_train, Y_train)\n",
    "y_pred= svr.predict(x_test)\n",
    "mae= print(f\"MAE is {mean_absolute_error(Y_test, y_pred)}\")\n",
    "# perm_importance= permutation_importance(svr, x_test, Y_test, n_repeats=10, random_state=2000, n_jobs=70)\n",
    "\n",
    "\n",
    "# imp_score=perm_importance.importances_mean\n",
    "# feature_indices = np.argsort(np.abs(imp_score))[::-1]\n",
    "# print(f\"Selected feature indices are {feature_indices}\")\n",
    "\n",
    "# # # Specify the number of features you want to select based on magnitude\n",
    "# num_selected_features = 100\n",
    "# top_100=feature_indices[:num_selected_features]\n",
    "# print(f\"Top 100 fearure indices are {feature_indices}\")\n",
    "# imp_score_100=imp_score[top_100]\n",
    "# print(f\"Top 100 fearures permutation scores are {imp_score_100}\")\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 is \", score)\n",
    "h= mean_absolute_error(y_pred,Y_test)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(y_pred, Y_test))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))\n",
    "# MI_SVR_sigSNP= M1.iloc[:,top_100]\n",
    "# MI_SVR_sig_col= list(MI_SVR_sigSNP.columns)\n",
    "# MI_SVR_sig_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score -6.636541741017606\n",
      "mean_absolute_error 26.3161754906064\n",
      "mean_squared_error  1228.7418391355063\n",
      "explained_variance_score -0.054511672815277246\n"
     ]
    }
   ],
   "source": [
    "regressor=xgb.XGBRegressor(learning_rate= 0.01, n_estimators=900,  max_depth=10, eval_metric='rmsle', random_state=2000)\n",
    "regressor.fit(x_train, Y_train)\n",
    "y_pred= regressor.predict(x_test)\n",
    "score= r2_score(y_pred, Y_test)\n",
    "print(\"r2 score\",score)\n",
    "h= mean_absolute_error(Y_test, y_pred)\n",
    "print(\"mean_absolute_error\", h)\n",
    "print(\"mean_squared_error \", mean_squared_error(Y_test, y_pred))\n",
    "print(\"explained_variance_score\", explained_variance_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
